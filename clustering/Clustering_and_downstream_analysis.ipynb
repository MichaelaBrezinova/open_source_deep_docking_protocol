{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Downstream Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.backends.backend_pdf\n",
    "import pickle\n",
    "from guacamol.common_scoring_functions import CNS_MPO_ScoringFunction\n",
    "from guacamol.utils.descriptors import mol_weight, logP, num_H_donors, tpsa, num_atoms, AtomCounter\n",
    "from contextlib import closing\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import SDWriter\n",
    "from rdkit import RDLogger\n",
    "import time\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "# import chemfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have a large number of molecules to cluster (3 million), we cannot use a traditional Butina clustering with RDKit. Following   https://www.macinchem.org/reviews/clustering/clustering.php we can cluster molecules with Chemfp, which does allow clustering larger libraries. We can use 1.x developer line, which is non-commercial. Important to note is that Chemfp 1.x is **not compatibile with Python 3**, hence we have to create a separate environment that will run the code in **Python 2.7**. All steps to create environment, install combatibile RDKit (versions before 2019) and finally chemfp iis shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -y -n DD_protocol_py27 python=2.7\n",
    "# conda activate DD_protocol_py27\n",
    "# conda install -c rdkit rdkit=2018.09.1\n",
    "# pip install chemfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to create a compatibile fingerprints from smiles for the molecules we want to cluster we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbatch --account=VENDRUSCOLO-SL3-CPU --partition=skylake --nodes=1 --ntasks=1 --cpus-per-task=10 --time=02:00:00 --wrap=\"rdkit2fps extracted_smiles.smi --fpSize 1024 --morgan --radius 2 --useChirality 1 > extracted_smiles.fps\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to get clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbatch --account=VENDRUSCOLO-SL3-CPU --partition=skylake --nodes=1 --ntasks=1 --cpus-per-task=15 --time=10:30:00 --wrap=\"python /home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/scripts_3/taylor_butina.py --profile --threshold 0.78 extracted_smiles.fps -o extracted_smiles_clusters.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at clusters and presence of 2D molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = pd.read_csv('clustering_results/clusters_1024_with_scores.txt', sep=\",\", header=None)\n",
    "molecules = molecules.rename(columns={0: 'molecule', 1: 'cluster', 2: 'score'})\n",
    "\n",
    "ligands_2d = pd.read_csv(\"clustering_results/molecule_testing/2D_ligands.txt\", names=['molecule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = pd.read_csv('extracted_smiles.smi', sep=\" \", names=['smile', 'molecule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.merge(smiles, ligands_2d, on='molecule')).to_csv('test_clustering_2d_molecules/2d_ligands.smi', index=False, header=False, sep=\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best predicted scoring molecule from each cluster\n",
    "\n",
    "First, lets get scores for all molecules that were clusters (merge cluster table with scores table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join -1 2 -2 1 -t , <(sort -k2 -t , clusters_1024.txt) <(sort -k1 -t , ../../id_score.csv) > clusters_1024_with_score.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get molecule with the highest score from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = pd.read_csv('clustering_results/clusters_1024_with_scores.txt', sep=\",\", header=None)\n",
    "molecules = molecules.rename(columns={0: 'molecule', 1: 'cluster', 2: 'score'})\n",
    "idx = molecules.groupby(\"cluster\")[\"score\"].transform(max) == molecules[\"score\"]\n",
    "best_scoring = molecules[idx]\n",
    "best_scoring = best_scoring.drop_duplicates(subset='cluster', keep=\"first\")\n",
    "# print(len(molecules[\"cluster\"].unique()))\n",
    "# print(len(best_scoring[\"cluster\"]))\n",
    "# print(len(best_scoring[\"cluster\"].unique()))\n",
    "# duplicates =  best_scoring[best_scoring[\"cluster\"].duplicated()]\n",
    "# best_scoring[best_scoring[\"score\"]==1][1:30]\n",
    "len(best_scoring['score'])\n",
    "best_scoring.molecule.to_csv('clustering_results/clusters_1024_best_scores.txt',index = False, header=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VINA DOCKING THE CLCUSTERING RESULTS AND ANALYSIS\n",
    "\n",
    "1. Process clusters and  singletons, isolate isomers ( have \"_\" in their ID ) and non-isomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘clustering_results/molecule_testing’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir clustering_results/molecule_testing\n",
    "!grep -v \"_\" clustering_results/clusters_1024_best_scores.txt > clustering_results/molecule_testing/clusters-no-isomers.txt\n",
    "!grep \"_\" clustering_results/clusters_1024_best_scores.txt > clustering_results/molecule_testing/clusters-isomers_ids.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get smiles for the molecules that will have conformations generated instead of downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = pd.read_csv(\"clustering_results/molecule_testing/clusters-isomers_ids.txt\", header=None)\n",
    "# ids = ids.rename(columns={0: 'ZINC_ID'})\n",
    "# smiles = pd.read_csv(\"extracted_smiles.smi\", sep=\" \", header=None)\n",
    "# smiles = smiles.rename(columns={0: 'smiles', 1: 'ZINC_ID'})\n",
    "# to_extract = pd.merge(ids, smiles, on='ZINC_ID')\n",
    "# to_extract = to_extract[['smiles', 'ZINC_ID']]\n",
    "# to_extract.to_csv(\"clustering_results/molecule_testing/clusters-isomers.smi\", sep=\" \", index = False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download/create based on if they are isomers or non-isomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "folder=$1\n",
      "n_cpus_per_node=$2\n",
      "name_cpu_partition=$3\n",
      "account_name=$4\n",
      "\n",
      "# Create directory where to store ligands. Directory is called pdbqt despite us downloading SDFs as we are going to convert\n",
      "# them later.\n",
      "pdbqt_directory=\"pdbqt\"\n",
      "mkdir -p ${folder}/$pdbqt_directory  || { echo 'Error creating directory' ; exit 1; }\n",
      "\n",
      "\n",
      "#### DO DOWNLOAD FOR ALL MOLECULES THAT ARE NOT HAVING ISOMERS ####\n",
      "# For each file of form (*-no-isomers.txt) [* = clusters] perform \n",
      "# the download of sdfs for all ZINC IDs contained in them\n",
      "echo \"Downloading ligands for molecules that do not have geometric isomers\"\n",
      "for f in ${folder}/clusters-no-isomers.txt\n",
      "do\n",
      "   tmp=\"$f\"\n",
      "   filename=\"${tmp##*/}\"\n",
      "   set_type=\"${filename%%-*}\" # clusters\n",
      "   \n",
      "   mkdir -p ${folder}/${pdbqt_directory}/${set_type}_download || { echo 'Error creating directory' ; exit 1; }\n",
      "   mkdir -p ${folder}/${set_type}_set_scripts || { echo 'Error creating directory' ; exit 1; }\n",
      "   \n",
      "   # Create scripts to download SDFs of chunks of size 1000\n",
      "   python ../scripts_3/create_download_ligand_scripts.py -file $f -path_to_store_scripts ${folder}/${set_type}_set_scripts -path_to_store_ligands ${folder}/${pdbqt_directory}/${set_type}_download --remove_ZINC_name\n",
      "\n",
      "   # Run separate download job for each batch of 100\n",
      "   for f in ${folder}/${set_type}_set_scripts/*.sh;\n",
      "   do dos2unix $f;sbatch -N 1 -n 1 --time=00:30:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition $f;\n",
      "   done\n",
      "done\n",
      "\n",
      "#### CREATE LIGANDS FOR ALL MOLECULES THAT ARE HAVING ISOMERS ####\n",
      "# For each file that contains the smiles for specific dataset (clusters), split the file into chunks of 1000 and generate 3D conformations\n",
      "echo \"Creating ligands for molecules with geometric isomers\"\n",
      "for f in ${folder}/clusters-isomers.smi\n",
      "do\n",
      "   tmp=\"$f\"\n",
      "   filename=\"${tmp##*/}\"\n",
      "   set_type=\"${filename%%-*}\" # clusters\n",
      "   \n",
      "   # Create directory that will contain ligands for the specific set (clusters)\n",
      "   mkdir -p ${folder}/${pdbqt_directory}/${set_type}_creation || { echo 'Error creating directory' ; exit 1; }\n",
      "   \n",
      "   # Split the file containing smiles into chunks of 1000\n",
      "   split -l 1000 $f ${folder}/${pdbqt_directory}/${set_type}_creation/chunk_\n",
      "   \n",
      "   # Run the 3D conformation tool for each of the chunks in parallel\n",
      "   for file_with_smiles in ${folder}/${pdbqt_directory}/${set_type}_creation/*\n",
      "   do\n",
      "       echo \"create job for ${file_with_smiles}\" \n",
      "       # Parameters set for slurm come from the user's input. However, if there are specific cluster requirements/changes needed\n",
      "       # please add them here.\n",
      "       sbatch -N 1 -n 1 --time=10:00:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition --wrap \"python ../scripts_3/smi2sdf.py -n 1 -j $n_cpus_per_node -i $file_with_smiles -o $file_with_smiles.sdf;\"\n",
      "   done \n",
      "done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat download_and_create_conformations.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare downloaded/created conformations for docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --account VENDRUSCOLO-SL3-CPU\n",
      "#SBATCH --partition skylake\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=10\n",
      "#SBATCH --time=04:00:00\n",
      "\n",
      "module load gcc\n",
      "module load boost-1.66.0-gcc-5.4.0-sdffwvs\n",
      "\n",
      "folder=$1\n",
      "name_cpu_partition=$2\n",
      "account_name=$3\n",
      "obabel_path=$4\n",
      "\n",
      "path_to_pdbqt=${folder}/pdbqt\n",
      "\n",
      " #For each dataset (download/creation) go over the sdf files containing the chunk of ligand conformations and split them so we have\n",
      " # 1 sdf per ligand conformation. Store these single sdf files within \"chunk\" directory that contains all sdfs coming from the larger sdf file, so these directories can be process in parallel in next steps.\n",
      " for d in ${path_to_pdbqt}/clusters_creation;\n",
      " do\n",
      " tmp=\"$d\"\n",
      " directory_set_name=\"${tmp##*/}\"\n",
      " echo \"Processing SDFs in ${directory_set_name}\"\n",
      "    for f in $d/*.sdf\n",
      "    do\n",
      "        tmp=\"$f\"\n",
      "        full_filename=\"${tmp##*/}\"\n",
      "        filename=\"${full_filename%.*}\"\n",
      "        echo \"Processing ${filename}\"\n",
      "        mkdir -p $d/${filename} \n",
      "        python ../scripts_3/split_sdfs.py -file $f -path_to_store $d/${filename}\n",
      "    done\n",
      " done\n",
      "\n",
      "#For all chunks within each dataset (creation/download), convert the single sdf files into pdbqt format.\n",
      "for d in ${path_to_pdbqt}/clusters_creation;\n",
      "do\n",
      "tmp=\"$d\"\n",
      "directory_set_name=\"${tmp##*/}\"\n",
      "echo \"Processing SDFs in ${directory_set_name}\"\n",
      "   for sub_d in $d/*/\n",
      "   do\n",
      "       echo \"Processing ${sub_d}\"\n",
      "       sbatch --account $account_name --partition $name_cpu_partition --nodes=1 --ntasks=1 --cpus-per-task=10 --time=00:30:00 ../scripts_3/run_obabel.sh $sub_d $obabel_path\n",
      "   done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!cat prepare_conformations_for_docking.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Check if downloads were successful (if everything was downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "shopt -s extglob\n",
      "\n",
      "folder=$1 # main folder with results\n",
      "chunk_size=$2 # how many compounds should the downloaded chunk contain\n",
      "chunk_pattern=$3 # naming pattern of downloaded chunk files\n",
      "# Go to directory with the current iteration\n",
      "cd $folder\n",
      "\n",
      "pdbqt_directory=\"pdbqt\"\n",
      "\n",
      "# For each batch file that has less compounds downloaded than $number_of_mols_to_expect, repeat the download\n",
      "echo \"**Retries required based on number of compounds**\"\n",
      "for d in ${pdbqt_directory}/*_download;\n",
      "do\n",
      "   tmp=\"$d\"\n",
      "   directory_set_name_full=\"${tmp##*/}\"\n",
      "   set_type=\"${directory_set_name_full%_*}\" # train/test/validation\n",
      "   echo \"Current set:\"\n",
      "   echo $set_type\n",
      "\n",
      "   echo \"Following downloads have to be repeated:\"\n",
      "   for f in $d/${chunk_pattern}\n",
      "   do\n",
      "       x=$(grep -wc \"\\$\\$\\$\\$\" < \"$f\")\n",
      "       if [ $x -lt ${chunk_size} ];\n",
      "       then\n",
      "           tmp=\"$f\"\n",
      "           full_filename=\"${tmp##*/}\"\n",
      "           filename=\"${full_filename%.*}\"\n",
      "           chunk_filename=${set_type}_set_scripts/${filename}.txt\n",
      "           added_prefix=${filename}_\n",
      "           echo \"Retrying script ${chunk_filename}\"\n",
      "       fi\n",
      "   done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!cat show_download_stats.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Retry downloads if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "shopt -s extglob\n",
      "\n",
      "#SBATCH --account VENDRUSCOLO-SL3-CPU\n",
      "#SBATCH --partition skylake\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=10\n",
      "#SBATCH --time=02:00:00\n",
      "\n",
      "folder=$1\n",
      "n_cpus_per_node=$2\n",
      "name_cpu_partition=$3\n",
      "account_name=$4\n",
      "original_chunk_size=$5\n",
      "original_chunk_pattern=$6\n",
      "new_chunk_size=$7\n",
      "\n",
      "# Go to directory with the current iteration\n",
      "cd $folder\n",
      "\n",
      "pdbqt_directory=\"pdbqt\"\n",
      "\n",
      "# For each batch file that has not been downloaded due to request failure, run the download again.\n",
      "echo \"retry based on number of lines\"\n",
      "for d in ${pdbqt_directory}/*_download;\n",
      "do\n",
      "tmp=\"$d\"\n",
      "directory_set_name_full=\"${tmp##*/}\"\n",
      "set_type=\"${directory_set_name_full%_*}\" # train/test/validation\n",
      "echo $set_type\n",
      "   for f in $d/${original_chunk_pattern}\n",
      "   do\n",
      "       x=$(wc -l < \"$f\")\n",
      "       if [ $x -lt 1000 ];\n",
      "       then\n",
      "           tmp=\"$f\"\n",
      "           full_filename=\"${tmp##*/}\"\n",
      "           filename=\"${full_filename%.*}\"\n",
      "           script_name=${set_type}_set_scripts/download_${filename}.sh\n",
      "           echo \"Retrying script ${script_name}\"\n",
      "        #    chmod u+x $script_name\n",
      "        #    ./$script_name\n",
      "       fi\n",
      "   done\n",
      "done\n",
      "\n",
      "# For each batch file that has less compounds downloaded than $number_of_mols_to_expect, repeat the download\n",
      "echo \"retry based on number of compounds\"\n",
      "for d in ${pdbqt_directory}/*_download;\n",
      "do\n",
      "tmp=\"$d\"\n",
      "directory_set_name_full=\"${tmp##*/}\"\n",
      "set_type=\"${directory_set_name_full%_*}\" # train/test/validation\n",
      "echo $set_type\n",
      "   for f in $d/${original_chunk_pattern}\n",
      "   do\n",
      "       x=$(grep -wc \"\\$\\$\\$\\$\" < \"$f\")\n",
      "       if [ $x -lt ${original_chunk_size} ];\n",
      "       then\n",
      "           tmp=\"$f\"\n",
      "           full_filename=\"${tmp##*/}\"\n",
      "           filename=\"${full_filename%.*}\"\n",
      "           chunk_filename=${set_type}_set_scripts/${filename}.txt\n",
      "           added_prefix=${filename}_\n",
      "           echo \"Creating subscripts for ${chunk_filename} of size ${new_chunk_size}\"\n",
      "        #    # Create scripts to download SDFs of chunks of size ${new_chunk_size}\n",
      "       #    python /home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/scripts_3/create_download_ligand_scripts.py -file ${chunk_filename} -path_to_store_scripts ${folder}/${set_type}_set_scripts -path_to_store_ligands ${folder}/${pdbqt_directory}/${set_type}_download -chunk_size ${new_chunk_size} -prefix_to_chunk_files ${added_prefix}\n",
      "           rm $f\n",
      "           # Run separate download job for each batch of 200\n",
      "           for subfile in ${folder}/${set_type}_set_scripts/download_${added_prefix}*.sh;\n",
      "            do dos2unix $subfile; echo \"Retrying script ${subfile}\"; sbatch -N 1 -n 1 --time=00:30:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition $subfile;\n",
      "           done\n",
      "       fi\n",
      "   done\n",
      "done\n",
      "\n",
      "# # For each batch file that has less compounds downloaded than $number_of_mols_to_expect, repeat the download\n",
      "# echo \"retry based on number of compounds\"\n",
      "# for d in ${pdbqt_directory}/*_download;\n",
      "# do\n",
      "# tmp=\"$d\"\n",
      "# directory_set_name_full=\"${tmp##*/}\"\n",
      "# set_type=\"${directory_set_name_full%_*}\" # train/test/validation\n",
      "# echo $set_type\n",
      "#    for f in $d/*.sdf\n",
      "#    do\n",
      "#        x=$(grep -wc \"\\$\\$\\$\\$\" < \"$f\")\n",
      "#        if [ $x -lt $number_of_mols_to_expect];\n",
      "#        then\n",
      "#            tmp=\"$f\"\n",
      "#            full_filename=\"${tmp##*/}\"\n",
      "#            filename=\"${full_filename%.*}\"\n",
      "#            script_name=${set_type}_set_scripts/download_${filename}.sh\n",
      "#            echo \"Retrying script ${script_name}\"\n",
      "#            chmod u+x $script_name\n",
      "#            ./$script_name\n",
      "#        fi\n",
      "#    done\n",
      "# done\n"
     ]
    }
   ],
   "source": [
    "!cat retry_downloads.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Dock the ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --account=VENDRUSCOLO-SL3-GPU\n",
      "#SBATCH --partition ampere\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --gres=gpu:1\n",
      "#SBATCH --job-name=phase_3\n",
      "#SBATCH --time=01:00:00\n",
      "\n",
      "# PARAMETERS\n",
      "folder=$1\n",
      "use_vina_gpu=$2\n",
      "account_name=$3\n",
      "partition=$4\n",
      "configuration_file=$5\n",
      "receptor=$6\n",
      "vina_path=$7\n",
      "\n",
      "\n",
      "# Establish paths used in docking for inputs (pdbqt directory) and outputs (docked directory)\n",
      "mkdir -p ${folder}/docked\n",
      "path_to_pdbqt=${folder}/pdbqt\n",
      "path_to_docked=${folder}/docked\n",
      "\n",
      "# For each set (creation/download) directory, create a matching directory in docked (output) directory and run batches within \n",
      "# each directory as a separate job.\n",
      "for d in ${path_to_pdbqt}/*;\n",
      "do\n",
      "    tmp=\"$d\"\n",
      "    directory_set_name=\"${tmp##*/}\"\n",
      "    echo \"Processing PDBQTs in ${directory_set_name}\"\n",
      "    # Create matching directory in docked (output) directory\n",
      "    mkdir -p ${path_to_docked}/${directory_set_name} || { echo 'Creating directory failed' ; exit 1; }\n",
      "    # For each batch within directory, run a separate docking job\n",
      "    for batch in $d/*/\n",
      "    do\n",
      "        tmp=\"$batch\"\n",
      "        trimmed_batch=\"${tmp%/}\"\n",
      "        echo \"Processing ${trimmed_batch} with output directory ${path_to_docked}/${directory_set_name}\" \n",
      "        sbatch --account $account_name --partition $partition ../scripts_3/run_batch_docking.sh ${trimmed_batch} $receptor $configuration_file ${path_to_docked}/${directory_set_name} $vina_path \"$use_vina_gpu\"\n",
      "    done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!cat vina_dock_conformations.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse VINA docked compounds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse docked compounds and get top 100000 best scoring molecules that will later be used for docking with FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python\n",
      "\n",
      "import sys\n",
      "sys.path.insert(0,\"../scripts_3\")\n",
      "from extract_scores_vina import extract_scores\n",
      "import pandas  as  pd\n",
      "import os, fnmatch\n",
      "from argparse import ArgumentParser\n",
      "\n",
      "# Helper function to convert the molecule to path to it\n",
      "def convert_to_filename(zinc_id, path_to_molecules):\n",
      "    if \"_\" in zinc_id:\n",
      "        return path_to_molecules + \"/clusters_creation/\" + zinc_id + \"_out.pdbqt\"\n",
      "    else:\n",
      "        return path_to_molecules + \"/clusters_download/\" + zinc_id + \"_out.pdbqt\"\n",
      "\n",
      "# # Helper function to find the molecule's docking output file\n",
      "# def find(pattern, path):\n",
      "#     result = []\n",
      "#     for root, dirs, files in os.walk(path):\n",
      "#         for name in files:\n",
      "#             if fnmatch.fnmatch(name, pattern):\n",
      "#                 result.append(os.path.join(root, name))\n",
      "#     return result\n",
      "\n",
      "def get_selected_molecules(directories_to_process, number_of_molecules_to_extract, path_to_molecules):\n",
      "    \n",
      "    # Get labels and corresponding ZINC_IDs\n",
      "    full_labels = extract_scores(directories_to_process)\n",
      "    full_labels[\"r_i_docking_score\"] = pd.to_numeric(full_labels[\"r_i_docking_score\"])\n",
      "    labels = full_labels.sort_values(by=\"r_i_docking_score\").head(int(number_of_molecules_to_extract))\n",
      "    labels[\"file\"] = labels.apply(lambda x: convert_to_filename(x['ZINC_ID'], path_to_molecules), axis=1)\n",
      "    return [full_labels, labels]\n",
      "\n",
      "def main():\n",
      "    # Parse arguments (directory to files to process)\n",
      "    parser = ArgumentParser()\n",
      "    parser.add_argument(\"-directory_prefix_to_process\", required=True,\n",
      "                        help=\"Directory prefix for directories (creation and download) with files to process\")\n",
      "    parser.add_argument(\"-path_to_store\", required=True,\n",
      "                        help=\"Path to store the processed output file\")\n",
      "    parser.add_argument(\"-path_to_molecules\", required=True,\n",
      "                        help=\"Path to where the output molecules from docking are stored\")\n",
      "    parser.add_argument(\"-number_of_molecules_to_extract\", default=100000, \n",
      "                        help=\"Number of best scoring molecules to extract\")\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    # For each prefix, there is download and creation directory \n",
      "    download_directory = args.directory_prefix_to_process + \"_download\"\n",
      "    creation_directory = args.directory_prefix_to_process + \"_creation\"\n",
      "    directories_to_process = [download_directory, creation_directory]\n",
      "\n",
      "    # Extract selected molecules and paths to their docking output files\n",
      "    results = get_selected_molecules(directories_to_process, \n",
      "                                                args.number_of_molecules_to_extract,\n",
      "                                                args.path_to_molecules)\n",
      "\n",
      "    # Extract singular name of processed directory\n",
      "    processed_directory_name = args.directory_prefix_to_process.split('/')[-1]\n",
      "    \n",
      "    # Store the molecules and their paths to a file\n",
      "    full_labels_file_name = processed_directory_name + \"_labels.txt\"\n",
      "    results[0].to_csv(args.path_to_store + \"/\" + full_labels_file_name, index=None, mode='a')\n",
      "\n",
      "    # Store the molecules and their paths to a file\n",
      "    labels_file_name = processed_directory_name + \"_selected_molecules.txt\"\n",
      "    results[1].to_csv(args.path_to_store + \"/\" + labels_file_name, index=None, mode='a')\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!cat analyse_docked_compounds.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = pd.read_csv(\"clustering_results/molecule_testing/clusters_labels.txt\",  delimiter=',')\n",
    "# labels[labels[\"r_i_docking_score\"] < -8.5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRED DOCKING AND ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=10\n",
      "#SBATCH --account=VENDRUSCOLO-SL3-CPU\n",
      "#SBATCH --partition skylake\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --job-name=fred_docking\n",
      "#SBATCH --time=01:00:00\n",
      "\n",
      "# obabel=/home/mb2462/test/DD_protocol_data/OPENBABEL/build/bin/obabel\n",
      "# oe_license=/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/oe_license.txt\n",
      "# receptor=/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/receptor.pdb\n",
      "# openeye=/home/mb2462/rds/hpc-work/DD/DD_protocol_data/openeye\n",
      "\n",
      "file_with_selected_molecules=$1\n",
      "directory_to_store=$2\n",
      "obabel=$3\n",
      "oe_license=$4\n",
      "receptor=$5\n",
      "openeye=$6\n",
      "n_cpus_per_node=$7\n",
      "name_cpu_partition=$8\n",
      "account_name=$9\n",
      "\n",
      "fred_directory=${directory_to_store}/fred_docked || { echo 'Creating directory failed' ; exit 1; }\n",
      "mkdir $fred_directory || { echo 'Changing directory directory failed' ; exit 1; }\n",
      "\n",
      "# Split the file containing smiles into chunks of 1000\n",
      "split -l 500 --additional-suffix=.txt ${file_with_selected_molecules} ${fred_directory}/chunk_ || { echo 'Splitting file failed' ; exit 1; }\n",
      "\n",
      "# Run the 3D conformation tool for each of the chunks in parallel\n",
      "for chunk_file in ${fred_directory}/chunk_*\n",
      "do\n",
      "    echo \"create job for fred docking of ${chunk_file}\" \n",
      "    # Parameters set for slurm come from the user's input. However, if there are specific cluster requirements/changes needed\n",
      "    # please add them here.\n",
      "    sbatch -N 1 -n 1 --time=07:30:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition ../scripts_3/batch_fred_docking.sh $chunk_file $fred_directory $obabel $oe_license $receptor $openeye\n",
      "    # ./../scripts_3/batch_fred_docking.sh $chunk_file $fred_directory $obabel $oe_license $receptor $openeye\n",
      "done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat fred_dock_conformations.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse FRED results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat results from chunks together (+ add which chunk the ligand belongs to). Further analysis is in **FINAL TOP MOLECULES** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in /home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/clustering_results/molecule_testing/fred_docked/*/*_docking_results.txt; do awk -F$'\\t' '{print $1, $2, FILENAME}' $f >> fred_docking_scores.txt; done"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL TOP MOLECULES\n",
    "\n",
    "There are multiple ways to define top molecules. Let us first get the molecules with Vina scores and with FRED scores and also sort them.  Here we are also doing adjustment by removing 2D molecules, which should not be necessary in the future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vina docked scores and fred scores\n",
    "vina_docked = pd.read_csv(\"clustering_results/molecule_testing/clusters_selected_molecules.txt\")\n",
    "fred_docked = pd.read_csv(\"clustering_results/molecule_testing/fred_docking_scores.txt\",delimiter=' ', names=['ZINC_ID', \"FRED_score\", \"chunk\"] )\n",
    "# get list of ligands that were 2D \n",
    "# TODO: remove the need to remove 2d ligands\n",
    "ligands_2d = pd.read_csv(\"clustering_results/molecule_testing/2D_ligands.txt\", names=['ZINC_ID'])\n",
    "\n",
    "# VINA cleanup - remove 2D ligands, sort by docking score and rename the headers\n",
    "vina_cleaned = pd.merge(vina_docked, ligands_2d, on='ZINC_ID',how='left', indicator=True)\n",
    "vina_cleaned =  vina_cleaned[vina_cleaned['_merge'] == 'left_only']\n",
    "vina_cleaned_sorted = vina_cleaned.sort_values('r_i_docking_score')\n",
    "vina_cleaned_sorted = vina_cleaned_sorted.drop('_merge',axis=1)\n",
    "vina_cleaned_sorted = vina_cleaned_sorted.rename(columns={'r_i_docking_score' : 'VINA_score', 'file': \"VINA_filename\"})\n",
    "\n",
    "# FRED cleanup - remove 2D ligands, sort by docking score and rename the headers\n",
    "fred_cleaned = pd.merge(fred_docked, ligands_2d, on='ZINC_ID',how='left', indicator=True)\n",
    "fred_cleaned =  fred_cleaned[fred_cleaned['_merge'] == 'left_only']\n",
    "fred_cleaned_sorted = fred_cleaned.sort_values('FRED_score')\n",
    "fred_cleaned_sorted = fred_cleaned_sorted.drop('_merge',axis=1)\n",
    "fred_cleaned_sorted['FRED_filename'] = fred_cleaned_sorted.apply(lambda x: x['chunk'].rsplit('/',1)[0] + '/out_files/' + x['ZINC_ID'] + '_fred_out.sdf', axis=1)\n",
    "fred_cleaned_sorted = fred_cleaned_sorted.drop('chunk',axis=1)\n",
    "\n",
    "\n",
    "ligands_both_scores = pd.merge(vina_cleaned_sorted, fred_cleaned_sorted, on='ZINC_ID')\n",
    "ligands_both_scores= ligands_both_scores[['ZINC_ID', \"VINA_score\", \"VINA_filename\", \"FRED_score\", \"FRED_filename\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_2ds = pd.merge(fred_docked, ligands_2d, on='ZINC_ID',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_score_2d = pd.merge(fred_docked, ligands_2d, on='ZINC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ligands_both_scores['VINA_score'].max())\n",
    "# print(ligands_both_scores['VINA_score'].min())\n",
    "# print(ligands_both_scores['FRED_score'].max())\n",
    "# print(ligands_both_scores['FRED_score'].min())\n",
    "\n",
    "# abs(ligands_both_scores['FRED_score'].max() - ligands_both_scores['FRED_score'].min())/abs(ligands_both_scores['VINA_score'].max() - ligands_both_scores['VINA_score'].min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 8000 and overlap\n",
    "Following code takes VINA and FRED scores for molecules, based on both scores, it sorts them respectively and takes top 8000 for each respectively. Then finds intersection of the top 8000 for both scores.\n",
    "\n",
    "Here we are also doing adjustment by removing 2D molecules, which should not be necessary in the future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8000_vina_cleaned_sorted = vina_cleaned_sorted.head(8000)\n",
    "top_8000_fred_cleaned_sorted = fred_cleaned_sorted.head(8000)\n",
    "\n",
    "top_8000_final_top= pd.merge(top_8000_vina_cleaned_sorted, top_8000_fred_cleaned_sorted, how='inner', on=['ZINC_ID'])\n",
    "\n",
    "top_8000_final_top = top_8000_final_top[['ZINC_ID', \"VINA_score\", \"FRED_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_8000_final_top.plot.scatter(x=\"VINA_score\", y=\"FRED_score\", title= \"Top overlap Top Ligands\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize scores and sum\n",
    "\n",
    "Use min-max normalization to get values between 0 and 1 for both scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ligands_both_scores = ligands_both_scores.copy()\n",
    "normalized_ligands_both_scores['VINA_score_normalized'] = (normalized_ligands_both_scores['VINA_score']-normalized_ligands_both_scores['VINA_score'].min())/(normalized_ligands_both_scores['VINA_score'].max()-normalized_ligands_both_scores['VINA_score'].min())\n",
    "normalized_ligands_both_scores['FRED_score_normalized'] = (normalized_ligands_both_scores['FRED_score']-normalized_ligands_both_scores['FRED_score'].min())/(normalized_ligands_both_scores['FRED_score'].max()-normalized_ligands_both_scores['FRED_score'].min())\n",
    "\n",
    "\n",
    "normalized_ligands_both_scores['joined_score_normalized'] = normalized_ligands_both_scores['VINA_score_normalized'] + normalized_ligands_both_scores['FRED_score_normalized']\n",
    "top_normalized_ligands_both_scores  = normalized_ligands_both_scores.sort_values('joined_score_normalized').head(1561)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_normalized_ligands_both_scores.plot.scatter(x=\"VINA_score\", y=\"FRED_score\",title=\"Normalized Sum Top Ligands\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined method - UPDATE: NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_normalized_ligands_both_scores = normalized_ligands_both_scores[normalized_ligands_both_scores['VINA_score'] <= top_8000_final_top['VINA_score'].max()]\n",
    "filtered_normalized_ligands_both_scores = filtered_normalized_ligands_both_scores[filtered_normalized_ligands_both_scores['FRED_score'] <= top_8000_final_top['FRED_score'].max()]\n",
    "top_filtered_normalized_ligands_both_scores = filtered_normalized_ligands_both_scores.sort_values('joined_score_normalized').head(1561)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled sum - UPDATE: identical to normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_sum_ligands_both_scores = ligands_both_scores.copy()\n",
    "scaled_sum_ligands_both_scores['combined_score'] = 5.367959411764706*scaled_sum_ligands_both_scores['VINA_score'] + scaled_sum_ligands_both_scores['FRED_score']\n",
    "top_scaled_sum_ligands_both_scores = scaled_sum_ligands_both_scores.sort_values('combined_score').head(1561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_scaled_sum_ligands_both_scores.plot.scatter(x='VINA_score', y='FRED_score', title=\"Scaled Sum Top Ligands\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands_top_8000_final_top = set(top_8000_final_top['ZINC_ID'])\n",
    "ligands_top_normalized_ligands_both_scores = set(top_normalized_ligands_both_scores['ZINC_ID'])\n",
    "ligands_top_scaled_sum_ligands_both_scores = set(top_scaled_sum_ligands_both_scores['ZINC_ID'])\n",
    "ligands_top_filtered_normalized_ligands_both_scores = set(top_filtered_normalized_ligands_both_scores['ZINC_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# venn3([ligands_top_8000_final_top, ligands_top_normalized_ligands_both_scores, ligands_top_filtered_normalized_ligands_both_scores], ('Top_overlap', 'Normalized_sum', 'Filtered_normalized_sum'))\n",
    "\n",
    "# plt.title(\"Overlap of top ligands using the 3 methods\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    /home/mb2462/rds/hpc-work/DD/DD_protocol_data/...\n",
       "Name: VINA_filename, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_consensus = pd.merge(top_8000_final_top, top_normalized_ligands_both_scores, on=['ZINC_ID'])\n",
    "top_consensus = top_consensus[['ZINC_ID', 'VINA_score_x', 'VINA_filename', 'FRED_score_x', 'FRED_filename']]\n",
    "top_consensus =top_consensus.rename(columns={'VINA_score_x' : 'VINA_score', 'FRED_score_x': \"FRED_score\"})\n",
    "top_consensus.to_csv(\"clustering_results/molecule_testing/top_consensus.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring consensus molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_consensus = pd.read_csv(\"clustering_results/molecule_testing/top_consensus.csv\", names=[\"ZINC_ID\", \"VINA_score\", \"VINA_filename\", \"FRED_score\", \"FRED_filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(top_consensus[\"VINA_score\"].min())\n",
    "# print(top_consensus[\"VINA_score\"].max())\n",
    "# print(top_consensus[\"FRED_score\"].min())\n",
    "# print(top_consensus[\"FRED_score\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking final 100\n",
    "\n",
    "## 1. Strict conditions for BBB penetration - NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppl = Chem.SDMolSupplier('clustering_results/molecule_testing/top_consensus_fred.sdf')\n",
    "# molecules = [x for x in Chem.ForwardSDMolSupplier(open('clustering_results/molecule_testing/top_consensus_fred.sdf')) if x is not None]\n",
    "molecules = [x for x in Chem.ForwardSDMolSupplier(open('/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/clustering_results/molecule_testing/top_consensus_fred.sdf','rb')) if x is not None]\n",
    "len(molecules)\n",
    "output_list = []\n",
    "for m in molecules:\n",
    "    if(m):\n",
    "        logP = Descriptors.MolLogP(m)\n",
    "        molWt = Descriptors.MolWt(m)\n",
    "        TPSA = Descriptors.TPSA(m)\n",
    "        HBD = Chem.rdMolDescriptors.CalcNumHBD(m)\n",
    "        if(logP <= 3 and molWt <= 360\n",
    "            and TPSA >= 40 and TPSA <= 90\n",
    "            and HBD <= 0.5):\n",
    "            output_list.append(m.GetProp('_Name'))\n",
    "# len(output_list)\n",
    "# output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for index,zinc_id in enumerate(top_consensus[\"ZINC_ID\"]):\n",
    "    if zinc_id in output_list:\n",
    "        indexes.append(index)\n",
    "\n",
    "# print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_consensus.iloc[indexes]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering of top consensus - NOT USED , molecules are too different based on the first clustering\n",
    "\n",
    "First lets prepare put sdf files of top ligands together to one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!awk -F',' '{print $NF}' top_consensus.csv > top_consensus_fred_filenames.txt\n",
    "#!while read p; do cat $p >> top_consensus_fred.sdf; done <top_consensus_fred_filenames.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda activate DD_protocol_py27\n",
    "#! rdkit2fps top_consensus_fred.sdf --fpSize 1024 --morgan --radius 2 --useChirality 1 > top_consensus_fred.fps\n",
    "#! sbatch --account=VENDRUSCOLO-SL3-CPU --partition=skylake --nodes=1 --ntasks=1 --cpus-per-task=10 --time=02:00:00 --wrap=\"python /home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/scripts_3/taylor_butina.py --profile --threshold 0.78 top_consensus_fred_check.fps -o top_consensus_fred_check_clusters.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using DeePred-BBB and Gaucamol MPO scoring\n",
    "1. Get smiles from (FRED) SDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ../scripts_3/sdftosmile.py -file clustering_results/molecule_testing/top_consensus_fred.sdf -path_to_store clustering_results/molecule_testing \n",
    "\n",
    "#!cp clustering_results/molecule_testing/top_consensus_fred.smi /home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/smiles.smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use DeePred-BBB (https://github.com/12rajnish/DeePred-BBB) to get permeability prediction (altered code to display scores rounded to 2 decimal places instead of 0 vs 1 - line 19 and 20 in DeePred-BBB_Script.py should be changed to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = loaded_model.predict(bbb_user_input).round(2)\n",
    "#prediction = prediction[:,0].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process results (prediction.csv and feature.csv) and get the top 100 molecules. Create  table merging their feature scores, VINA score, FRED score and path to their Vina and FRED sdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_loginq = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/feature.csv\")\n",
    "# prediction_loginq = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/prediction.csv\", header=None, names=[\"Predicted\"])\n",
    "\n",
    "# feature = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/results_used/feature.csv\")\n",
    "# prediction = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/results_used/prediction.csv\", header=None, names=[\"Predicted\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merged_loginq = pd.merge(feature_loginq, prediction_loginq, left_index=True, right_index=True)\n",
    "# merged= pd.read_csv(\"clustering_results/molecule_testing/top_consensus_permeability_without_changes.csv\")\n",
    "\n",
    "# # all_merged = pd.merge(merged, merged_loginq, on=\"Name\")\n",
    "# # all_merged[all_merged[\"Name\"]==\"ZINC000226296427\"][[\"Name\",\"Predicted_x\", \"Predicted_y\"]]\n",
    "# shortened = pd.merge(merged,predbbb, on=\"Name\")[[\"Name\", \"ALogP_x\", \"ALogP_y\", \"Predicted_x\", \"Predicted_y\"]]\n",
    "# # shortened['Predicted_x_rounded'] = shortened.Predicted_x.round()\n",
    "# # shortened = shortened.dropna()\n",
    "# shortened['difference'] = shortened['Predicted_x'] - shortened['Predicted_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_consensus = pd.read_csv(\"clustering_results/molecule_testing/top_consensus.csv\", names=[\"Name\", \"VINA_score\", \"VINA_filename\", \"FRED_score\", \"FRED_filename\"])\n",
    "top_consensus_fred_filenames = top_consensus[[\"Name\", \"FRED_filename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predbbb_feature = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/results_used/feature.csv\")\n",
    "# predbbb_prediction = pd.read_csv(\"/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DeePred-BBB-main/DeePred-BBB/results_used/prediction.csv\", header=None, names=[\"Predicted\"])\n",
    "# predbbb_merged = pd.merge(feature, prediction, left_index=True, right_index=True)\n",
    "predbbb = pd.read_csv(\"clustering_results/molecule_testing/top_consensus_permeability_tensor.csv\")\n",
    "predbbb = predbbb.sort_values(by=['Predicted'],ascending=False)\n",
    "predbbb.to_csv(\"clustering_results/molecule_testing/top_consensus_deeppredbbb_sorted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Get CNS_MPO Guacamol scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = [x for x in Chem.ForwardSDMolSupplier(open('/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/clustering_results/molecule_testing/top_consensus_fred.sdf','rb')) if x is not None]\n",
    "mpo_scores = []\n",
    "mpo_names = []\n",
    "mpo_mw = []\n",
    "mpo_lp = []\n",
    "mpo_hbd = []\n",
    "mpo_mol_tpsa = []\n",
    "CNS = CNS_MPO_ScoringFunction()\n",
    "for mol in molecules:\n",
    "    score = CNS.score_mol(mol)\n",
    "    mpo_scores.append(score)\n",
    "    mpo_names.append(mol.GetProp('_Name'))\n",
    "    mpo_mw.append(mol_weight(mol))\n",
    "    mpo_lp.append(logP(mol))\n",
    "    mpo_hbd.append(num_H_donors(mol))\n",
    "    mpo_mol_tpsa.append(tpsa(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpo_dict = {'Name' : mpo_names, \n",
    "            'Mol_Weight': mpo_mw, \n",
    "            'LogP' : mpo_lp, \n",
    "            'Num_H_donors' : mpo_hbd, \n",
    "            \"TPSA\" : mpo_mol_tpsa,\n",
    "            'MPO_score':mpo_scores}\n",
    "mpo= pd.DataFrame(mpo_dict)\n",
    "mpo= mpo.sort_values(by=\"MPO_score\", ascending=False)\n",
    "# mpo.to_csv(\"clustering_results/molecule_testing/top_consensus_mpo.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_mpo_predbbb = pd.merge(mpo, predbbb, on=\"Name\")\n",
    "# merged_mpo_predbbb_vina_fred_scores  =  pd.merge(merged_mpo_predbbb, top_consensus, on=\"Name\")\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores = merged_mpo_predbbb_vina_fred_scores[[\"Name\", 'Mol_Weight', 'LogP', \"Num_H_donors\", \"TPSA\", \"MPO_score\", \"Predicted\", \"VINA_score\", \"FRED_score\"]]\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores = clean_merged_mpo_predbbb_vina_fred_scores.rename(columns={'Predicted': 'DeePred-BBB Prediction'}) \n",
    "# clean_merged_mpo_predbbb_vina_fred_scores.to_csv(\"clustering_results/molecule_testing/top_consensus_all_scores.csv\")\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores\n",
    "\n",
    "clean_merged_mpo_predbbb_vina_fred_scores = pd.read_csv(\"clustering_results/molecule_testing/top_consensus_all_scores.csv\")\n",
    "clean_merged_mpo_predbbb_vina_fred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = matplotlib.backends.backend_pdf.PdfPages(\"top_consensus_all_scores_graphs.pdf\")\n",
    "# fig = plt.figure(dpi=100, figsize=(14, 7)) \n",
    "# plt.scatter(clean_merged_mpo_predbbb_vina_fred_scores['VINA_score'],\n",
    "#             clean_merged_mpo_predbbb_vina_fred_scores['FRED_score'],\n",
    "#             c= clean_merged_mpo_predbbb_vina_fred_scores['MPO_score'],  cmap='viridis', alpha=0.65)\n",
    "\n",
    "\n",
    "# cbar = plt.colorbar()\n",
    "# cbar.ax.get_yaxis().labelpad = 15\n",
    "# cbar.ax.set_ylabel('MPO_score', rotation=270)\n",
    "# plt.xlabel('VINA_score')\n",
    "# plt.ylabel('FRED_score')\n",
    "# plt.title('VINA, FRED and MPO scores for top molecules')\n",
    "# pdf.savefig( fig )\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=100, figsize=(14, 7)) \n",
    "\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores = clean_merged_mpo_predbbb_vina_fred_scores[clean_merged_mpo_predbbb_vina_fred_scores['DeePred-BBB Prediction']>-1]\n",
    "# plt.scatter(clean_merged_mpo_predbbb_vina_fred_scores['VINA_score'],\n",
    "#             clean_merged_mpo_predbbb_vina_fred_scores['FRED_score'],\n",
    "#             c=clean_merged_mpo_predbbb_vina_fred_scores['DeePred-BBB Prediction'],  cmap='viridis',  alpha=0.65)\n",
    "\n",
    "# # clean_merged_mpo_predbbb_vina_fred_scores['marker'] = clean_merged_mpo_predbbb_vina_fred_scores['DeePred-BBB Prediction'].apply(lambda x: 'o' if x>0 else 'x')\n",
    "# # for marker, d in clean_merged_mpo_predbbb_vina_fred_scores.groupby('marker'):\n",
    "# #     plt.scatter(x=d['VINA_score'], y=d['FRED_score'], c=d['MPO_score'], marker=marker, label=marker)\n",
    "# # plt.legend()\n",
    "\n",
    "\n",
    "# cbar = plt.colorbar(ticks=np.linspace(0,1,2))\n",
    "# cbar.ax.get_yaxis().labelpad = 15\n",
    "# cbar.ax.set_ylabel('DeePred-BBB Prediction', rotation=270)\n",
    "# plt.xlabel('VINA_score')\n",
    "# plt.ylabel('FRED_score')\n",
    "# plt.title('VINA, FRED scores and DeePred-BBB prediction for top molecules')\n",
    "# pdf.savefig( fig )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_merged_mpo_predbbb_vina_fred_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3651645/3868065991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_merged_mpo_predbbb_vina_fred_scores_passing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_merged_mpo_predbbb_vina_fred_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_merged_mpo_predbbb_vina_fred_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DeePred-BBB Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_merged_mpo_predbbb_vina_fred_scores_passing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_merged_mpo_predbbb_vina_fred_scores_passing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_merged_mpo_predbbb_vina_fred_scores_passing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MPO_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_merged_mpo_predbbb_vina_fred_scores' is not defined"
     ]
    }
   ],
   "source": [
    "clean_merged_mpo_predbbb_vina_fred_scores_passing = clean_merged_mpo_predbbb_vina_fred_scores[clean_merged_mpo_predbbb_vina_fred_scores['DeePred-BBB Prediction']==1]\n",
    "clean_merged_mpo_predbbb_vina_fred_scores_passing = clean_merged_mpo_predbbb_vina_fred_scores_passing[clean_merged_mpo_predbbb_vina_fred_scores_passing['MPO_score']>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=100, figsize=(14, 7)) \n",
    "\n",
    "# plt.scatter(clean_merged_mpo_predbbb_vina_fred_scores_passing['VINA_score'],\n",
    "#             clean_merged_mpo_predbbb_vina_fred_scores_passing['FRED_score'],\n",
    "#             c=clean_merged_mpo_predbbb_vina_fred_scores_passing['MPO_score'],  cmap='viridis',  alpha=0.65)\n",
    "\n",
    "# cbar = plt.colorbar()\n",
    "# cbar.ax.get_yaxis().labelpad = 15\n",
    "# cbar.ax.set_ylabel('MPO_score', rotation=270)\n",
    "# plt.xlabel('VINA_score')\n",
    "# plt.ylabel('FRED_score')\n",
    "# plt.title('VINA and FRED scores for molecules passing DeePred-BBB and having MPO scores > 0.9')\n",
    "# pdf.savefig( fig )\n",
    "# plt.show()\n",
    "# pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold = clean_merged_mpo_predbbb_vina_fred_scores_passing.copy(deep=True)\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['FRED_threshold_for_Vina'] = clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['VINA_score'].apply(lambda x: -2.75*x-139/5 )\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['threshold_pass'] = clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold.apply(lambda x: 1 if x['FRED_score'] <= x['FRED_threshold_for_Vina'] else 0, axis=1)\n",
    "# clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold[clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['threshold_pass']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = matplotlib.backends.backend_pdf.PdfPages(\"selection_based_on_diagonal.pdf\")\n",
    "# fig = plt.figure(dpi=100, figsize=(14, 7)) \n",
    "\n",
    "# plt.scatter(clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['VINA_score'],\n",
    "#             clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['FRED_score'],\n",
    "#             c=clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['threshold_pass'],  cmap='viridis',  alpha=0.65)\n",
    "\n",
    "# x_diagonal = np.linspace(-8, -7.2, 100)\n",
    "# y_diagonal = -2.755*x_diagonal-139/5\n",
    "# plt.plot(x_diagonal, y_diagonal, c=\"red\")\n",
    "# # cbar.ax.set_ylabel('Threshold pass', rotation=270)\n",
    "# plt.xlabel('VINA_score')\n",
    "# plt.ylabel('FRED_score')\n",
    "# plt.title('Selected molecules to experimentally test')\n",
    "# pdf.savefig( fig )\n",
    "# plt.show()\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clean_merged_mpo_predbbb_vina_fred_scores_passing =  clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold[clean_merged_mpo_predbbb_vina_fred_scores_passing_with_threshold['threshold_pass']==1]\n",
    "selected_clean_merged_mpo_predbbb_vina_fred_scores_passing.to_csv('clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_top_consensus_fred_filenames_only = pd.merge(selected_clean_merged_mpo_predbbb_vina_fred_scores_passing, top_consensus_fred_filenames, on=\"Name\")[[\"FRED_filename\"]]\n",
    "selected_top_consensus_fred_filenames_only.to_csv('clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_fred_filenames.csv',  index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get also less stringent list of molecules to test (59 molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold = clean_merged_mpo_predbbb_vina_fred_scores_passing.copy(deep=True)\n",
    "clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['FRED_threshold_for_Vina'] = clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['VINA_score'].apply(lambda x: -2.75*x-135.5/5 )\n",
    "clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['threshold_pass'] = clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold.apply(lambda x: 1 if x['FRED_score'] <= x['FRED_threshold_for_Vina'] else 0, axis=1)\n",
    "len(clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold[clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['threshold_pass']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = matplotlib.backends.backend_pdf.PdfPages(\"selection_based_on_diagonal_less_strict.pdf\")\n",
    "# fig = plt.figure(dpi=100, figsize=(14, 7)) \n",
    "\n",
    "# plt.scatter(clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['VINA_score'],\n",
    "#             clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['FRED_score'],\n",
    "#             c=clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['threshold_pass'],  cmap='viridis',  alpha=0.65)\n",
    "\n",
    "# x_diagonal = np.linspace(-7.8, -7.2, 100)\n",
    "# y_diagonal = -2.755*x_diagonal-135.5/5\n",
    "# plt.plot(x_diagonal, y_diagonal, c=\"red\")\n",
    "# # cbar.ax.set_ylabel('Threshold pass', rotation=270)\n",
    "# plt.xlabel('VINA_score')\n",
    "# plt.ylabel('FRED_score')\n",
    "# plt.title('Selected molecules to experimentally test')\n",
    "# pdf.savefig( fig )\n",
    "# plt.show()\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_looser_threshold_clean_merged_mpo_predbbb_vina_fred_scores_passing =  clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold[clean_merged_mpo_predbbb_vina_fred_scores_passing_with_looser_threshold['threshold_pass']==1]\n",
    "selected_looser_threshold_clean_merged_mpo_predbbb_vina_fred_scores_passing.to_csv('clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_less_strict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_looser_threshold_top_consensus_fred_filenames_only = pd.merge(selected_looser_threshold_clean_merged_mpo_predbbb_vina_fred_scores_passing, top_consensus_fred_filenames, on=\"Name\")[[\"FRED_filename\"]]\n",
    "selected_looser_threshold_top_consensus_fred_filenames_only.to_csv('clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_less_strict_fred_filenames.csv',  index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Get SDFs of selected top molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!while read p; do cat \"$p\" >> clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test.sdf ; done<clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_fred_filenames.csv\n",
    "#!while read p; do cat \"$p\" >> clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_less_strict.sdf ; done<clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test_less_strict_fred_filenames.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecules = [x for x in Chem.ForwardSDMolSupplier(open('/home/mb2462/rds/hpc-work/DD/DD_protocol_data/DD_main_clean/clustering/clustering_results/molecule_testing/top_consensus_fred.sdf','rb')) if x is not None]\n",
    "# # mol.GetProp('_Name')\n",
    "# with Chem.SDWriter('clustering_results/molecule_testing/top_consensus_selected_to_experimentally_test.sdf') as w:\n",
    "#     for m in molecules:\n",
    "#         print(m.GetProp('_Name'))\n",
    "#         if selected_clean_merged_mpo_predbbb_vina_fred_scores_passing['Name'].str.contains(m.GetProp('_Name')).any():\n",
    "#             w.write(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful (bash commands)\n",
    "\n",
    "1. Get line(s) that contain the given string (\"the_string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grep -hnr \"singletons\" extracted_smiles_clusters_1024_full.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSOLETE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles(\"Cc1nc(on1)c2ccc(nc2)NCc3ccc(cc3)N4CCCC4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = AllChem.GetHashedMorganFingerprint(m, 2, nBits=2048)\n",
    "# array = np.zeros((0,), dtype=np.int8)\n",
    "# DataStructs.ConvertToNumpyArray(fp, array)\n",
    "# print(array[array.nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   4,    8,   12,   23,   33,   36,   75,   80,  102,  128,  136,\n",
      "        233,  248,  255,  265,  310,  356,  378,  381,  392,  407,  428,\n",
      "        439,  456,  463,  511,  518,  607,  638,  656,  680,  687,  698,\n",
      "        726,  730,  801,  831,  836,  849,  896,  897,  926,  935,  967,\n",
      "        974,  980, 1023]),)\n"
     ]
    }
   ],
   "source": [
    "fp2 = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=1024, useChirality=True)\n",
    "array2 = np.zeros((0, ), dtype=np.int8)\n",
    "DataStructs.ConvertToNumpyArray(fp2, array2)\n",
    "print(array2.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arena = chemfp.load_fingerprints(\"clustering/testing_chemfp/test_smiles-isomers_1024.fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bz = Chem.MolFromSmiles('c1ccccc1')\n",
    "# fp_bz = AllChem.GetMorganFingerprintAsBitVect(bz,radius=2,nBits=1024)\n",
    "# pyr = Chem.MolFromSmiles('c1ccccc1')\n",
    "# fp_pyr = AllChem.GetMorganFingerprintAsBitVect(pyr,radius=2,nBits=1024)\n",
    "# print(\"Similarity:\",DataStructs.TanimotoSimilarity(fp_bz,fp_pyr))\n",
    "\n",
    "# print(\"intersection count:\",(fp_bz&fp_pyr).GetNumOnBits())\n",
    "# print(\"union count:\",(fp_bz|fp_pyr).GetNumOnBits())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRED RESULTS\n",
    "\n",
    "Concat results into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in fred_docked/*/*_docking_results.txt; do awk -F$'\\t' '{print $1, $2, FILENAME}' $f >> fred_docking_scores.txt; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python get_top_molecules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# sort -t$',' -n -k 1  clusters_selected_molecules.txt | awk -F$',' '{print $2}' > VINA_sorted_100K.txt\n",
    "# sort -t$'\\t' -n -k 2  fred_docking_scores.txt | awk -F$'\\t' '{print $1}' > FRED_sorted_100K.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vina_docked = pd.read_csv(\"clustering_results/molecule_testing/clusters_selected_molecules.txt\")\n",
    "# fred_docked = pd.read_csv(\"clustering_results/molecule_testing/fred_docking_scores.txt\",delimiter=' ', names=['ZINC_ID', \"FRED_score\", \"chunk\"] )\n",
    "# ligands_2d = pd.read_csv(\"clustering_results/molecule_testing/2D_ligands.txt\", names=['ZINC_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_1000 = pd.read_csv(\"clustering_results/molecule_testing/final_selected_1000.csv\")\n",
    "\n",
    "# top_1000  = top_1000.drop('VINA_filename', axis=1)\n",
    "# top_1000  = top_1000.drop('FRED_filename', axis=1)\n",
    "# top_1000  = top_1000.drop(top_1000.columns[0], axis=1)\n",
    "# top_1000 = top_1000.sort_values('FRED_score')\n",
    "# # top_1000.to_csv('clustering_results/molecule_testing/final_selected_only_scores.csv', index=False)\n",
    "\n",
    "\n",
    "# vina_cleaned = pd.merge(vina_docked, ligands_2d, on='ZINC_ID',how='left', indicator=True)\n",
    "# vina_cleaned =  vina_cleaned[vina_cleaned['_merge'] == 'left_only']\n",
    "# vina_cleaned_sorted = vina_cleaned.sort_values('r_i_docking_score')\n",
    "# vina_cleaned_sorted = vina_cleaned_sorted.drop('file',axis=1)\n",
    "# vina_cleaned_sorted = vina_cleaned_sorted.drop('_merge',axis=1)\n",
    "# # vina_cleaned_sorted.to_csv('clustering_results/molecule_testing/sorted_vina_scores.csv', index=False)\n",
    "\n",
    "# fred_cleaned = pd.merge(fred_docked, ligands_2d, on='ZINC_ID',how='left', indicator=True)\n",
    "# fred_cleaned =  fred_cleaned[fred_cleaned['_merge'] == 'left_only']\n",
    "# fred_cleaned_sorted = fred_cleaned.sort_values('FRED_score')\n",
    "# fred_cleaned_sorted = fred_cleaned_sorted.drop('chunk',axis=1)\n",
    "# fred_cleaned_sorted = fred_cleaned_sorted.drop('_merge',axis=1)\n",
    "# # fred_cleaned_sorted.to_csv('clustering_results/molecule_testing/sorted_fred_scores.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fred_cleaned_sorted\n",
    "# top_1000.sort_values('VINA_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligands_both_scores = pd.merge(vina_cleaned_sorted, fred_cleaned_sorted, on='ZINC_ID')\n",
    "# ligands_both_scores= ligands_both_scores[['ZINC_ID', \"r_i_docking_score\", \"FRED_score\"]]\n",
    "# ligands_both_scores = ligands_both_scores.rename(columns={'r_i_docking_score' : \"VINA_score\"})\n",
    "# # ligands_both_scores.to_csv('clustering_results/molecule_testing/vina_and_fred_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligands_both_scores['VINA_score_normalized'] = (ligands_both_scores['VINA_score']-ligands_both_scores['VINA_score'].min())/(ligands_both_scores['VINA_score'].max()-ligands_both_scores['VINA_score'].min())\n",
    "# ligands_both_scores['FRED_score_normalized'] = (ligands_both_scores['FRED_score']-ligands_both_scores['FRED_score'].min())/(ligands_both_scores['FRED_score'].max()-ligands_both_scores['FRED_score'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligands_both_scores['joined_score_normalized'] = ligands_both_scores['VINA_score_normalized'] + ligands_both_scores['FRED_score_normalized']\n",
    "# ligands_both_scores.sort_values('joined_score_normalized').head(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DD_protocol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d519bf512d1246025acf4bd36fe1f59837b3571e4b79001cebd1b3ad0794f74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and Downstream Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from contextlib import closing\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "import chemfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have a large number of molecules to cluster (3 million), we cannot use a traditional Butina clustering with RDKit. Following   https://www.macinchem.org/reviews/clustering/clustering.php we can cluster molecules with Chemfp, which does allow clustering larger libraries. We can use 1.x developer line, which is non-commercial. Important to note is that Chemfp 1.x is **not compatibile with Python 3**, hence we have to create a separate environment that will run the code in **Python 2.7**. All steps to create environment, install combatibile RDKit (versions before 2019) and finally chemfp iis shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -y -n DD_protocol_py27 python=2.7\n",
    "# conda activate DD_protocol_py27\n",
    "# conda install -c rdkit rdkit=2018.09.1\n",
    "# pip install chemfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to create a compatibile fingerprints from smiles for the molecules we want to cluster we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbatch --account=VENDRUSCOLO-SL3-CPU --partition=skylake --nodes=1 --ntasks=1 --cpus-per-task=10 --time=02:00:00 --wrap=\"rdkit2fps extracted_smiles.smi --fpSize 1024 --morgan --radius 2 --useChirality 1 > extracted_smiles.fps\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to get clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbatch --account=VENDRUSCOLO-SL3-CPU --partition=skylake --nodes=1 --ntasks=1 --cpus-per-task=15 --time=10:30:00 --wrap=\"python ../scripts_3/taylor_butina.py --profile --threshold 0.78 extracted_smiles.fps -o extracted_smiles_clusters.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing clustering results\n",
    "\n",
    "1. Process clusters and  singletons, isolate isomers ( have \"_\" in their ID ) and non-isomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "# PROCESS SINGLETONS AND PREPARE THEIR IDS INTO A SEPARATE FILE\n",
      "\n",
      "sed '5q;d' extracted_smiles_clusters_1024_full.txt > extracted_smiles_clusters_1024_singletons.txt\n",
      "while IFS=\" \" read -r -a line; do printf \"%s\\n\" \"${line[@]}\"; done < extracted_smiles_clusters_1024_singletons.txt > extracted_smiles_clusters_1024_singletons_clean_with_header.txt\n",
      "tail -n +2 extracted_smiles_clusters_1024_singletons_clean_with_header.txt  > extracted_smiles_clusters_1024_singletons_clean.txt\n",
      "rm extracted_smiles_clusters_1024_singletons_clean_with_header.txt\n",
      "rm extracted_smiles_clusters_1024_singletons.txt\n",
      "mv extracted_smiles_clusters_1024_singletons_clean.txt extracted_smiles_clusters_1024_singletons.txt\n",
      "\n",
      "# SEPARATE MOLECULES TO ONES THAT ARE ISOMER AND THE ONES THAT ARE NOT\n",
      "mkdir clustering_results/clusters_and_singletons\n",
      "grep -v \"_\" clustering_results/extracted_smiles_clusters_1024.txt > clustering_results/clusters_and_singletons/clusters-no-isomers.txt\n",
      "grep -v \"_\" clustering_results/extracted_smiles_clusters_1024_singletons.txt > clustering_results/clusters_and_singletons/singletons-no-isomers.txt\n",
      "\n",
      "grep \"_\" clustering_results/extracted_smiles_clusters_1024.txt > clustering_results/clusters_and_singletons/clusters-isomers_ids.txt\n",
      "grep \"_\" clustering_results/extracted_smiles_clusters_1024_singletons.txt > clustering_results/clusters_and_singletons/singletons-isomers_ids.txt\n",
      "\n",
      "grep -f clustering_results/clusters_and_singletons/clusters-isomers_ids.txt extracted_smiles.smi > clustering_results/clusters_and_singletons/clusters-isomers.smi\n",
      "grep -f clustering_results/clusters_and_singletons/singletons-isomers_ids.txt extracted_smiles.smi > clustering_results/clusters_and_singletons/singletons-isomers.smi\n"
     ]
    }
   ],
   "source": [
    "!cat process_clusters_and_singletons.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare selected molecules (download/create based on if they are isomers or non-isomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "folder=$1\n",
      "n_cpus_per_node=$2\n",
      "name_cpu_partition=$3\n",
      "account_name=$4\n",
      "\n",
      "# Create directory where to store ligands. Directory is called pdbqt despite us downloading SDFs as we are going to convert\n",
      "# them later.\n",
      "pdbqt_directory=\"pdbqt\"\n",
      "mkdir -p ${folder}/$pdbqt_directory  || { echo 'Error creating directory' ; exit 1; }\n",
      "\n",
      "\n",
      "#### DO DOWNLOAD FOR ALL MOLECULES THAT ARE NOT HAVING ISOMERS ####\n",
      "# For each file of form (*-no-isomers.txt) [* = clusters/singletons] perform \n",
      "# the download of sdfs for all ZINC IDs contained in them\n",
      "echo \"Downloading ligands for molecules that do not have geometric isomers\"\n",
      "for f in ${folder}/singletons-no-isomers.txt\n",
      "do\n",
      "   tmp=\"$f\"\n",
      "   filename=\"${tmp##*/}\"\n",
      "   set_type=\"${filename%%-*}\" # clusters/singletons\n",
      "   \n",
      "   mkdir -p ${folder}/${pdbqt_directory}/${set_type}_download || { echo 'Error creating directory' ; exit 1; }\n",
      "   mkdir -p ${folder}/${set_type}_set_scripts || { echo 'Error creating directory' ; exit 1; }\n",
      "   \n",
      "   # Create scripts to download SDFs of chunks of size 1000\n",
      "   python ../scripts_3/create_download_ligand_scripts.py -file $f -path_to_store_scripts ${folder}/${set_type}_set_scripts -path_to_store_ligands ${folder}/${pdbqt_directory}/${set_type}_download\n",
      "\n",
      "   # Run separate download job for each batch of 1000\n",
      "   for f in ${folder}/${set_type}_set_scripts/*.sh;\n",
      "   do dos2unix $f;sbatch -N 1 -n 1 --time=00:30:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition $f;\n",
      "   done\n",
      "done\n",
      "\n",
      "#### CREATE LIGANDS FOR ALL MOLECULES THAT ARE HAVING ISOMERS ####\n",
      "# For each file that contains the smiles for specific dataset (clusters/singletons), split the file into chunks of 1000 and generate 3D conformations\n",
      "echo \"Creating ligands for molecules with geometric isomers\"\n",
      "for f in ${folder}/singletons-isomers.smi\n",
      "do\n",
      "   tmp=\"$f\"\n",
      "   filename=\"${tmp##*/}\"\n",
      "   set_type=\"${filename%%-*}\" # clusters/singletons\n",
      "   \n",
      "   # Create directory that will contain ligands for the specific set (clusters/singletons)\n",
      "   mkdir -p ${folder}/${pdbqt_directory}/${set_type}_creation || { echo 'Error creating directory' ; exit 1; }\n",
      "   \n",
      "   # Split the file containing smiles into chunks of 1000\n",
      "   split -l 1000 $f ${folder}/${pdbqt_directory}/${set_type}_creation/chunk_\n",
      "   \n",
      "   # Run the 3D conformation tool for each of the chunks in parallel\n",
      "   for file_with_smiles in ${folder}/${pdbqt_directory}/${set_type}_creation/*\n",
      "   do\n",
      "       echo \"create job for ${file_with_smiles}\" \n",
      "       # Parameters set for slurm come from the user's input. However, if there are specific cluster requirements/changes needed\n",
      "       # please add them here.\n",
      "       sbatch -N 1 -n 1 --time=10:00:00 --cpus-per-task=$n_cpus_per_node --account=$account_name --partition=$name_cpu_partition --wrap \"python ../scripts_3/smi2sdf.py -n 1 -j $n_cpus_per_node -i $file_with_smiles -o $file_with_smiles.sdf;\"\n",
      "   done \n",
      "done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat prepare_selected_molecules.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful (bash commands)\n",
    "\n",
    "1. Get line(s) that contain the given string (\"the_string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grep -hnr \"singletons\" extracted_smiles_clusters_1024_full.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chem.MolFromSmiles(\"Cc1nc(on1)c2ccc(nc2)NCc3ccc(cc3)N4CCCC4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = AllChem.GetHashedMorganFingerprint(m, 2, nBits=2048)\n",
    "# array = np.zeros((0,), dtype=np.int8)\n",
    "# DataStructs.ConvertToNumpyArray(fp, array)\n",
    "# print(array[array.nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   4,    8,   12,   23,   33,   36,   75,   80,  102,  128,  136,\n",
      "        233,  248,  255,  265,  310,  356,  378,  381,  392,  407,  428,\n",
      "        439,  456,  463,  511,  518,  607,  638,  656,  680,  687,  698,\n",
      "        726,  730,  801,  831,  836,  849,  896,  897,  926,  935,  967,\n",
      "        974,  980, 1023]),)\n"
     ]
    }
   ],
   "source": [
    "fp2 = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=1024, useChirality=True)\n",
    "array2 = np.zeros((0, ), dtype=np.int8)\n",
    "DataStructs.ConvertToNumpyArray(fp2, array2)\n",
    "print(array2.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arena = chemfp.load_fingerprints(\"clustering/testing_chemfp/test_smiles-isomers_1024.fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bz = Chem.MolFromSmiles('c1ccccc1')\n",
    "# fp_bz = AllChem.GetMorganFingerprintAsBitVect(bz,radius=2,nBits=1024)\n",
    "# pyr = Chem.MolFromSmiles('c1ccccc1')\n",
    "# fp_pyr = AllChem.GetMorganFingerprintAsBitVect(pyr,radius=2,nBits=1024)\n",
    "# print(\"Similarity:\",DataStructs.TanimotoSimilarity(fp_bz,fp_pyr))\n",
    "\n",
    "# print(\"intersection count:\",(fp_bz&fp_pyr).GetNumOnBits())\n",
    "# print(\"union count:\",(fp_bz|fp_pyr).GetNumOnBits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DD_protocol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d519bf512d1246025acf4bd36fe1f59837b3571e4b79001cebd1b3ad0794f74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
